{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fb9705-eba7-40f2-8433-803b47e19b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Description: This file is the main file for running the Random Forest model. It imports the necessary libraries and modules, and sets up the logger. It also imports the necessary libraries for the model and sets up the logger.\n",
    "#---------------------------- Imports -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "here= os.getcwd\n",
    "root = os.path.dirname(os.path.abspath(__name__))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0e9245-1119-4b05-842a-0888351df378",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (166206180.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    def initialize_logger(log_file=\"logfile%s.log\" %time.strftime(\"%Y%m%d%H%M%S\")):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#---------------------------- Logger Done -------------------------------\n",
    "#---------------------------- Imports for the model -------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss , f1_score ,accuracy_score, roc_auc_score, precision_score, recall_score , confusion_matrix ,mean_absolute_error, mean_squared_error, median_absolute_error,r2_score\n",
    "from sklearn.model_selection import GridSearchCV  ,StratifiedKFold  ,cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "#---------------------------- function to import data -------------------------------\n",
    "def import_data(name):\n",
    "    \"\"\"Import data.\"\"\"\n",
    "    data = pd.read_csv(os.path.join(here, name))\n",
    "    return data\n",
    "\n",
    "#---------------------------- import data -------------------------------\n",
    "try:\n",
    "    X_train = import_data('X_train_df.csv')\n",
    "    y_train = import_data('y_train.csv')\n",
    "    X_test = import_data('X_test_df.csv')\n",
    "    y_test = import_data('y_test.csv')\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(\"File not found: %s\", e)\n",
    "    sys.exit(1)\n",
    "except pd.errors.EmptyDataError as e:\n",
    "    \n",
    "#---------------------------- initialize_logger -------------------------------\n",
    "def initialize_logger(log_file=\"logfile%s.log\" %time.strftime(\"%Y%m%d%H%M%S\")):\n",
    "    \"\"\"Initialize logger.\"\"\"\n",
    "    log_directory = os.path.join(here, 'logs')\n",
    "    try:\n",
    "        if not os.path.exists(log_directory):\n",
    "            os.makedirs(log_directory)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating log directory: {e}\")\n",
    "        raise\n",
    "\n",
    "    log_file_path = os.path.join(log_directory, log_file)\n",
    "    \n",
    "    try:\n",
    "        logging.basicConfig(filename=log_file_path, level=logging.INFO, \n",
    "                            format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                            datefmt='%d-%b-%y %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up logger configuration: {e}\")\n",
    "        raise\n",
    "    return logging.getLogger()\n",
    "initialize_logger()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info('Logger initialized')\n",
    "#---------------------------- Logger Done -------------------------------\n",
    "#---------------------------- Imports for the model -------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss , f1_score ,accuracy_score, roc_auc_score, precision_score, recall_score , confusion_matrix ,mean_absolute_error, mean_squared_error, median_absolute_error,r2_score\n",
    "from sklearn.model_selection import GridSearchCV  ,StratifiedKFold  ,cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "#---------------------------- function to import data -------------------------------\n",
    "def import_data(name):\n",
    "    \"\"\"Import data.\"\"\"\n",
    "    data = pd.read_csv(os.path.join(here, name))\n",
    "    return data\n",
    "\n",
    "#---------------------------- import data -------------------------------\n",
    "try:\n",
    "    X_train = import_data('X_train_df.csv')\n",
    "    y_train = import_data('y_train.csv')\n",
    "    X_test = import_data('X_test_df.csv')\n",
    "    y_test = import_data('y_test.csv')\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(\"File not found: %s\", e)\n",
    "    sys.exit(1)\n",
    "except pd.errors.EmptyDataError as e:\n",
    "    logging.error(\"Empty data found while importing: %s\", e)\n",
    "    sys.exit(1)\n",
    "\n",
    "#---------------------------- DropColumns -------------------------------\n",
    "try:\n",
    "    columns = ['diag_3_365.44', 'repaglinide_Down']\n",
    "    X_train = X_train.drop(columns, axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error dropping columns: {e}\")\n",
    "    raise\n",
    "\n",
    "#---------------------------- Splitting the train set into train and validation set in 80:20 -------------------------------\n",
    "try:\n",
    "    X_train_es, X_val, y_train_es, y_val = train_test_split(X_train, y_train, shuffle=True, random_state=42)\n",
    "except Exception as e:\n",
    "    print(f\"Error splitting the train set: {e}\")\n",
    "    raise\n",
    "\n",
    "#---------------------------- create a GridSearchCV object -------------------------------\n",
    "def get_params(RunParasSearch=False):\n",
    "    if RunParasSearch:\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        return {\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False],\n",
    "            'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "    else:\n",
    "        # Define a single set of parameters for direct model instantiation\n",
    "        return {\n",
    "            'bootstrap': False,\n",
    "            'max_depth': 20,\n",
    "            'max_features': 'sqrt',\n",
    "            'min_samples_leaf': 2,\n",
    "            'min_samples_split': 20,\n",
    "            'n_estimators': 200\n",
    "        }\n",
    "params = get_params(RunParasSearch=False)\n",
    "param_grid = get_params(RunParasSearch=True)\n",
    "#---------------------------- create a Random Forest model -------------------------------\n",
    "def create_model(params, random_state=42, n_jobs=-1):\n",
    "    model = RandomForestClassifier(random_state=random_state, n_jobs=n_jobs, **params)\n",
    "    return model\n",
    "rf_model = create_model(params)\n",
    "#---------------------------- create a CV and GridSearchCV object ---------------------------------\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "rf_grid_search = GridSearchCV(estimator= rf_model, param_grid= param_grid, cv=cv, scoring='neg_log_loss', n_jobs=-1, verbose=2)\n",
    "#---------------------------- fit the model no hyperparameter tuning with sklearn -------------------------------\n",
    "rf_model.fit(X_train_es, y_train_es)\n",
    "#---------------------------- predict the model -------------------------------\n",
    "def predict_model(model, X_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    rf_pre_Proba= model.predict_proba(X_val)    \n",
    "    return y_pred , rf_pre_Proba\n",
    "\n",
    "y_pred, rf_pre_Proba = predict_model(rf_model, X_val)\n",
    "log_loss1 = log_loss(y_val, rf_pre_Proba)\n",
    "print('logloss1 - no hyperparameter tuning with sklearn', log_loss1)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(rf_model, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "print('logloss1 - no hyperparameter tunning with sk_cv', cv_results['test_score'].mean())\n",
    "\n",
    "#---------------------------- fit the model with hyperparameter tuning ------------------------------\n",
    "rf_grid_search.fit(X_train_es, y_train_es)\n",
    "#---------------------------- predict the model ------------------------------\n",
    "y_pred, rf_pre_Proba = predict_model(rf_grid_search, X_val)\n",
    "logloss3 = log_loss(y_val, rf_pre_Proba)\n",
    "print('logloss3 - hyperparameter tuning with sklearn', logloss3)\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(rf_grid_search, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "print('logloss3 - hyperparameter tunning with sk_cv', cv_results['test_score'].mean())\n",
    "\n",
    "#---------------------------- fit the model with best hyperparameters ------------------------------\n",
    "best_params = rf_grid_search.best_params_\n",
    "print('Best hyperparameters:', best_params)\n",
    "rf_best = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf_best.fit(X_train_es, y_train_es)\n",
    "predictions = rf_best.predict_proba(X_val)\n",
    "log_loss4 = log_loss(y_val, predictions)\n",
    "print('logloss4 - best hyperparameter tuning with sklearn', log_loss4)\n",
    "#---------------------------- # Feature Importance ------------------------------\n",
    "feature_importances = rf_best.feature_importances_\n",
    "print('Feature Importance:', feature_importances)\n",
    "\n",
    "#---------------------------- genarate 15 random seeds and calculate the mean log loss ------------------------------\n",
    "def generate_prediction_and_feature_tables(X_train, y_train, X_test, y_test, best_params):\n",
    "    # Generating prediction and feature importance tables on 15 different seeds:\n",
    "    prediction_table = pd.DataFrame()\n",
    "    scores = [log_loss, roc_auc_score]\n",
    "    scores_cm = [precision_score, recall_score, accuracy_score]\n",
    "\n",
    "    feature_importance_table = pd.DataFrame()\n",
    "\n",
    "    for i in range(15):\n",
    "        best_model = RandomForestClassifier(**best_params, random_state=i)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds_test = best_model.predict_proba(X_test)\n",
    "        preds_cm = best_model.predict(X_test)\n",
    "\n",
    "        # Storing scores in the prediction table\n",
    "        for score in scores:\n",
    "            prediction_table.loc['seed_' + str(i), score.__name__] = score(y_test, preds_test[:, 1])\n",
    "        for score in scores_cm:\n",
    "            prediction_table.loc['seed_' + str(i), score.__name__] = score(y_test, preds_cm)\n",
    "\n",
    "        # Storing feature importances\n",
    "        feature_importance_table.loc['seed_' + str(i)] = best_model.feature_importances_\n",
    "\n",
    "    # Export the prediction table to a CSV file\n",
    "    prediction_table.to_csv('prediction_table.csv')\n",
    "\n",
    "    # Export feature importance data\n",
    "    feature_importance_table.to_csv('feature_importance.csv')\n",
    "\n",
    "    # Optional: Create and save a feature importance plot (requires additional plotting libraries)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    feature_importance_table.mean().sort_values(ascending=False).plot(kind='bar', ax=ax)\n",
    "    plt.title('Average Feature Importances Across Seeds')\n",
    "    plt.savefig('feature_importances.png')\n",
    "\n",
    "# Call the function\n",
    "generate_prediction_and_feature_tables(X_train, y_train, X_test, y_test, best_params)\n",
    "\n",
    "##---------------------------- Dummy Classifier and Default Model Comparison ------------------------------\n",
    "def dummy_classifier_comparison(X_train, y_train, X_test, y_test):\n",
    "    # Dummy classifier for baseline comparison\n",
    "    strategies = ['most_frequent', 'uniform', 'constant']\n",
    "    constants = [None, None, 1]  # constant value only used with 'constant' strategy\n",
    "\n",
    "    for strategy, constant in zip(strategies, constants):\n",
    "        dummy_clf = DummyClassifier(strategy=strategy, random_state=42, constant=constant)\n",
    "        dummy_clf.fit(X_train, y_train)\n",
    "        dummy_pred = dummy_clf.predict(X_test)\n",
    "        dummy_proba = dummy_clf.predict_proba(X_test)\n",
    "        print('Strategy used:', strategy)\n",
    "        for score in scores:\n",
    "            print(score.__name__, round(score(y_test, dummy_proba[:, 1]), 5))\n",
    "        for score in scores_cm:\n",
    "            print(score.__name__, round(score(y_test, dummy_pred), 5))\n",
    "\n",
    "    # Comparing the best model with a default parameters model\n",
    "    def_params = {'n_estimators': 100, 'max_depth': None}  # Default parameters for RandomForest\n",
    "\n",
    "    default_rf = RandomForestClassifier(**def_params, random_state=42)\n",
    "    default_rf.fit(X_train, y_train)\n",
    "    default_pred_proba = default_rf.predict_proba(X_test)\n",
    "    for score in scores:\n",
    "        print(score.__name__ + ' - default params', round(score(y_test, default_pred_proba[:, 1]), 5))\n",
    "\n",
    "    print(\"Training Time: %s seconds\" % (str(time.time() - start_time)))\n",
    "\n",
    "# Call the function\n",
    "dummy_classifier_comparison(X_train, y_train, X_test, y_test)\n",
    ".error(\"Empty data found while importing: %s\", e)\n",
    "    sys.exit(1)\n",
    "\n",
    "#---------------------------- DropColumns -------------------------------\n",
    "try:\n",
    "    columns = ['diag_3_365.44', 'repaglinide_Down']\n",
    "    X_train = X_train.drop(columns, axis=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error dropping columns: {e}\")\n",
    "    raise\n",
    "\n",
    "#---------------------------- Splitting the train set into train and validation set in 80:20 -------------------------------\n",
    "try:\n",
    "    X_train_es, X_val, y_train_es, y_val = train_test_split(X_train, y_train, shuffle=True, random_state=42)\n",
    "except Exception as e:\n",
    "    print(f\"Error splitting the train set: {e}\")\n",
    "    raise\n",
    "\n",
    "#---------------------------- create a GridSearchCV object -------------------------------\n",
    "def get_params(RunParasSearch=False):\n",
    "    if RunParasSearch:\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        return {\n",
    "            'n_estimators': [10, 50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False],\n",
    "            'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "    else:\n",
    "        # Define a single set of parameters for direct model instantiation\n",
    "        return {\n",
    "            'bootstrap': False,\n",
    "            'max_depth': 20,\n",
    "            'max_features': 'sqrt',\n",
    "            'min_samples_leaf': 2,\n",
    "            'min_samples_split': 20,\n",
    "            'n_estimators': 200\n",
    "        }\n",
    "params = get_params(RunParasSearch=False)\n",
    "param_grid = get_params(RunParasSearch=True)\n",
    "#---------------------------- create a Random Forest model -------------------------------\n",
    "def create_model(params, random_state=42, n_jobs=-1):\n",
    "    model = RandomForestClassifier(random_state=random_state, n_jobs=n_jobs, **params)\n",
    "    return model\n",
    "rf_model = create_model(params)\n",
    "#---------------------------- create a CV and GridSearchCV object ---------------------------------\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "rf_grid_search = GridSearchCV(estimator= rf_model, param_grid= param_grid, cv=cv, scoring='neg_log_loss', n_jobs=-1, verbose=2)\n",
    "#---------------------------- fit the model no hyperparameter tuning with sklearn -------------------------------\n",
    "rf_model.fit(X_train_es, y_train_es)\n",
    "#---------------------------- predict the model -------------------------------\n",
    "def predict_model(model, X_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    rf_pre_Proba= model.predict_proba(X_val)    \n",
    "    return y_pred , rf_pre_Proba\n",
    "\n",
    "y_pred, rf_pre_Proba = predict_model(rf_model, X_val)\n",
    "log_loss1 = log_loss(y_val, rf_pre_Proba)\n",
    "print('logloss1 - no hyperparameter tuning with sklearn', log_loss1)\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(rf_model, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "print('logloss1 - no hyperparameter tunning with sk_cv', cv_results['test_score'].mean())\n",
    "\n",
    "#---------------------------- fit the model with hyperparameter tuning ------------------------------\n",
    "rf_grid_search.fit(X_train_es, y_train_es)\n",
    "#---------------------------- predict the model ------------------------------\n",
    "y_pred, rf_pre_Proba = predict_model(rf_grid_search, X_val)\n",
    "logloss3 = log_loss(y_val, rf_pre_Proba)\n",
    "print('logloss3 - hyperparameter tuning with sklearn', logloss3)\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(rf_grid_search, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "print('logloss3 - hyperparameter tunning with sk_cv', cv_results['test_score'].mean())\n",
    "\n",
    "#---------------------------- fit the model with best hyperparameters ------------------------------\n",
    "best_params = rf_grid_search.best_params_\n",
    "print('Best hyperparameters:', best_params)\n",
    "rf_best = RandomForestClassifier(**best_params, random_state=42)\n",
    "rf_best.fit(X_train_es, y_train_es)\n",
    "predictions = rf_best.predict_proba(X_val)\n",
    "log_loss4 = log_loss(y_val, predictions)\n",
    "print('logloss4 - best hyperparameter tuning with sklearn', log_loss4)\n",
    "#---------------------------- # Feature Importance ------------------------------\n",
    "feature_importances = rf_best.feature_importances_\n",
    "print('Feature Importance:', feature_importances)\n",
    "\n",
    "#---------------------------- genarate 15 random seeds and calculate the mean log loss ------------------------------\n",
    "def generate_prediction_and_feature_tables(X_train, y_train, X_test, y_test, best_params):\n",
    "    # Generating prediction and feature importance tables on 15 different seeds:\n",
    "    prediction_table = pd.DataFrame()\n",
    "    scores = [log_loss, roc_auc_score]\n",
    "    scores_cm = [precision_score, recall_score, accuracy_score]\n",
    "\n",
    "    feature_importance_table = pd.DataFrame()\n",
    "\n",
    "    for i in range(15):\n",
    "        best_model = RandomForestClassifier(**best_params, random_state=i)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds_test = best_model.predict_proba(X_test)\n",
    "        preds_cm = best_model.predict(X_test)\n",
    "\n",
    "        # Storing scores in the prediction table\n",
    "        for score in scores:\n",
    "            prediction_table.loc['seed_' + str(i), score.__name__] = score(y_test, preds_test[:, 1])\n",
    "        for score in scores_cm:\n",
    "            prediction_table.loc['seed_' + str(i), score.__name__] = score(y_test, preds_cm)\n",
    "\n",
    "        # Storing feature importances\n",
    "        feature_importance_table.loc['seed_' + str(i)] = best_model.feature_importances_\n",
    "\n",
    "    # Export the prediction table to a CSV file\n",
    "    prediction_table.to_csv('prediction_table.csv')\n",
    "\n",
    "    # Export feature importance data\n",
    "    feature_importance_table.to_csv('feature_importance.csv')\n",
    "\n",
    "    # Optional: Create and save a feature importance plot (requires additional plotting libraries)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    feature_importance_table.mean().sort_values(ascending=False).plot(kind='bar', ax=ax)\n",
    "    plt.title('Average Feature Importances Across Seeds')\n",
    "    plt.savefig('feature_importances.png')\n",
    "\n",
    "# Call the function\n",
    "generate_prediction_and_feature_tables(X_train, y_train, X_test, y_test, best_params)\n",
    "\n",
    "##---------------------------- Dummy Classifier and Default Model Comparison ------------------------------\n",
    "def dummy_classifier_comparison(X_train, y_train, X_test, y_test):\n",
    "    # Dummy classifier for baseline comparison\n",
    "    strategies = ['most_frequent', 'uniform', 'constant']\n",
    "    constants = [None, None, 1]  # constant value only used with 'constant' strategy\n",
    "\n",
    "    for strategy, constant in zip(strategies, constants):\n",
    "        dummy_clf = DummyClassifier(strategy=strategy, random_state=42, constant=constant)\n",
    "        dummy_clf.fit(X_train, y_train)\n",
    "        dummy_pred = dummy_clf.predict(X_test)\n",
    "        dummy_proba = dummy_clf.predict_proba(X_test)\n",
    "        print('Strategy used:', strategy)\n",
    "        for score in scores:\n",
    "            print(score.__name__, round(score(y_test, dummy_proba[:, 1]), 5))\n",
    "        for score in scores_cm:\n",
    "            print(score.__name__, round(score(y_test, dummy_pred), 5))\n",
    "\n",
    "    # Comparing the best model with a default parameters model\n",
    "    def_params = {'n_estimators': 100, 'max_depth': None}  # Default parameters for RandomForest\n",
    "\n",
    "    default_rf = RandomForestClassifier(**def_params, random_state=42)\n",
    "    default_rf.fit(X_train, y_train)\n",
    "    default_pred_proba = default_rf.predict_proba(X_test)\n",
    "    for score in scores:\n",
    "        print(score.__name__ + ' - default params', round(score(y_test, default_pred_proba[:, 1]), 5))\n",
    "\n",
    "    print(\"Training Time: %s seconds\" % (str(time.time() - start_time)))\n",
    "\n",
    "# Call the function\n",
    "dummy_classifier_comparison(X_train, y_train, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
