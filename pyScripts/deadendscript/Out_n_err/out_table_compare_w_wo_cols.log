[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015839 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015446 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016635 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008841 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010488 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010824 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008892 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008966 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008929 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009332 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015981 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016565 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013649 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008723 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008764 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008569 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008985 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011154 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008456 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970

------------------------------------------------------------
Sender: LSF System <DoNotReply>
Subject: Job 19347: <compare_w_wo> in cluster <wexac> Done

Job <compare_w_wo> was submitted from host <access4> by user <guyilan> in cluster <wexac> at Wed Mar 20 18:23:52 2024
Job was executed on host(s) <4*cn587>, in queue <new-short>, as user <guyilan> in cluster <wexac> at Wed Mar 20 18:23:58 2024
</home/labs/antebilab/guyilan> was used as the home directory.
</home/labs/antebilab/guyilan/ML project/ML_Project/pyScripts> was used as the working directory.
Started at Wed Mar 20 18:23:58 2024
Terminated at Wed Mar 20 18:51:06 2024
Results reported at Wed Mar 20 18:51:06 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python compare_w_wo_cols.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1791.00 sec.
    Max Memory :                                 1324 MB
    Average Memory :                             1195.58 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               31444.00 MB
    Max Swap :                                   -
    Max Processes :                              8
    Max Threads :                                28
    Run time :                                   1629 sec.
    Turnaround time :                            1634 sec.

The output (if any) is above this job summary.



PS:

Read file <error_table_compare_w_wo_cols.log> for stderr output of this job.

[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019371 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019198 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019322 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019012 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019331 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019503 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019226 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 452
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019157 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019225 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 453
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 121
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019056 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 451
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 120
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018914 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018779 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 406
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019161 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018871 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 406
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018895 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 406
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24125, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019000 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492498 -> initscore=-0.030011
[LightGBM] [Info] Start training from score -0.030011
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018999 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24859
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018898 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48985, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492518 -> initscore=-0.029930
[LightGBM] [Info] Start training from score -0.029930
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019181 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 407
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 119
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970
[LightGBM] [Info] Number of positive: 24126, number of negative: 24860
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018899 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 405
[LightGBM] [Info] Number of data points in the train set: 48986, number of used features: 118
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492508 -> initscore=-0.029970
[LightGBM] [Info] Start training from score -0.029970

------------------------------------------------------------
Sender: LSF System <DoNotReply>
Subject: Job 19481: <compare_w_wo> in cluster <wexac> Done

Job <compare_w_wo> was submitted from host <access4> by user <guyilan> in cluster <wexac> at Wed Mar 20 19:02:07 2024
Job was executed on host(s) <1*cn305>, in queue <new-short>, as user <guyilan> in cluster <wexac> at Wed Mar 20 19:02:08 2024
                            <1*cn601>
                            <1*cn615>
                            <1*cn427>
</home/labs/antebilab/guyilan> was used as the home directory.
</home/labs/antebilab/guyilan/ML project/ML_Project/pyScripts> was used as the working directory.
Started at Wed Mar 20 19:02:08 2024
Terminated at Wed Mar 20 19:26:12 2024
Results reported at Wed Mar 20 19:26:12 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python compare_w_wo_cols.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1409.00 sec.
    Max Memory :                                 1472 MB
    Average Memory :                             1298.76 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               31296.00 MB
    Max Swap :                                   -
    Max Processes :                              8
    Max Threads :                                19
    Run time :                                   1446 sec.
    Turnaround time :                            1445 sec.

The output (if any) is above this job summary.



PS:

Read file <error_table_compare_w_wo_cols.log> for stderr output of this job.

